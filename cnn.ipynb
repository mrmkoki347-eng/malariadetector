{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUJcsrG1iQHw"
   },
   "source": [
    "# **1. Data Prep**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7If7zTrKk6sp"
   },
   "source": [
    "**1: Imports & Configuration**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KXGbPSE_khKR",
    "outputId": "a99da688-f3bd-46ef-8ff5-904b90780ce8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Utilisation du device : cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "!pip install -q albumentations==1.3.1\n",
    "!pip install -q timm\n",
    "\n",
    "\n",
    "# Imports\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# Configuration du device (GPU)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Utilisation du device : {device}\")\n",
    "\n",
    "# random seed\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEgiwrPRlmKq"
   },
   "source": [
    "**2: T\u00e9l\u00e9chargement du Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "EiI7tuV7lmhY",
    "outputId": "6a6a54ca-33d6-4b7c-dc33-0bdf9e1ed3d3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Veuillez uploader votre fichier kaggle.json :\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-ccb808ce-4df7-4bec-8004-5551293929de\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-ccb808ce-4df7-4bec-8004-5551293929de\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving kaggle.json to kaggle (5).json\n",
      "T\u00e9l\u00e9chargement du dataset...\n",
      "Dataset URL: https://www.kaggle.com/datasets/iarunava/cell-images-for-detecting-malaria\n",
      "License(s): unknown\n",
      "cell-images-for-detecting-malaria.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "replace cell_images/Parasitized/C100P61ThinF_IMG_20150918_144104_cell_162.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
      "Dataset d\u00e9zipp\u00e9 avec succ\u00e8s !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab import files\n",
    "print(\"Veuillez uploader votre fichier kaggle.json :\")\n",
    "files.upload()\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "print(\"T\u00e9l\u00e9chargement du dataset...\")\n",
    "!kaggle datasets download -d iarunava/cell-images-for-detecting-malaria\n",
    "!unzip -q cell-images-for-detecting-malaria.zip\n",
    "print(\"Dataset d\u00e9zipp\u00e9 avec succ\u00e8s !\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOz-seaumBf-"
   },
   "source": [
    "\n",
    "**3: Organisation du chemin & Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "RigMpxKfmDPN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f461f2d0-62f9-4aa7-c302-2532c1a17ab5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total images : 27558\n",
      "Infect\u00e9es : 13779 | Saines : 13779\n",
      "Train size : 22046\n",
      "Val size   : 2756\n",
      "Test size  : 2756\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"cell_images\")\n",
    "\n",
    "\n",
    "parasitized = list(DATA_DIR.glob('Parasitized/*.png'))\n",
    "uninfected = list(DATA_DIR.glob('Uninfected/*.png'))\n",
    "\n",
    "df_parasitized = pd.DataFrame({'path': parasitized, 'label': 1})\n",
    "df_uninfected = pd.DataFrame({'path': uninfected, 'label': 0})\n",
    "\n",
    "\n",
    "df = pd.concat([df_parasitized, df_uninfected], axis=0).reset_index(drop=True)\n",
    "df['path'] = df['path'].astype(str)\n",
    "\n",
    "print(f\"Total images : {len(df)}\")\n",
    "print(f\"Infect\u00e9es : {len(df_parasitized)} | Saines : {len(df_uninfected)}\")\n",
    "\n",
    "# SPLIT\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n",
    "\n",
    "print(f\"Train size : {len(train_df)}\")\n",
    "print(f\"Val size   : {len(val_df)}\")\n",
    "print(f\"Test size  : {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GC3izTdmGwZ"
   },
   "source": [
    "**4: Malaria Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "wQ5Ny_aemHEJ"
   },
   "outputs": [],
   "source": [
    "class MalariaDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = row['path']\n",
    "        label = row['label']\n",
    "\n",
    "        # Lecture de l'image avec OpenCV\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feZsKL9ymUQY"
   },
   "source": [
    " **5: Data Augmentation & DataLoaders**"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 12\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "\n",
    "# -----Data Augmentation\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Rotate(limit=30, p=0.5),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.3),\n",
    "    A.CoarseDropout(max_holes=8, max_height=16, max_width=16, p=0.2), # Tr\u00e8s important\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "#----DataLoaders\n",
    "\n",
    "train_dataset = MalariaDataset(train_df, transform=train_transforms)\n",
    "val_dataset = MalariaDataset(val_df, transform=val_transforms)\n",
    "test_dataset = MalariaDataset(test_df, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(\"DataLoaders pr\u00eats !\")"
   ],
   "metadata": {
    "id": "EW3s9BXgkAi4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "397d2f3d-ba4c-40ee-e263-13039aee4089"
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DataLoaders pr\u00eats !\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6k6j4CmGwLP7"
   },
   "source": [
    "# **2. Mod\u00e8le & Entrainement**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1CvW8St7mUgA",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "4aab949acb3b463c94431af7d8873146",
      "a9dd6324c1db45bf8568ffe440300406",
      "07ee7ee8dbf54387971f72f7831144ac",
      "3eaff04bfa7a40f3b62fafc802b4459d",
      "d759b8b52d0d49ec9e6edad605e23e35",
      "208c414ae7164a45b7f1a2947154131b",
      "07fa59acc9ac49069204a293a55d3912",
      "4a4e4add65af4e5191f10d1f459dd6d6",
      "1196c2d10fc2416a8bd9da438b100ce8",
      "74a285f65e014ab1b6e2c97480c3256b",
      "68fc3fedf30547058a61c1c01623a2b9"
     ]
    },
    "outputId": "860d142e-ecc4-4d02-ea58-474fea7f4a40"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " PHASE 1 : WarmUp \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-1835113257.py:87: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/689 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4aab949acb3b463c94431af7d8873146"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "\n",
    "\n",
    "import timm\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class MalariaNetPro(nn.Module):\n",
    "    def __init__(self, model_name='efficientnet_b0', pretrained=True):\n",
    "        super(MalariaNetPro, self).__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        in_features = self.backbone.classifier.in_features\n",
    "\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone.forward_features(x)\n",
    "        x = self.gap(features)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.head(x)\n",
    "\n",
    "model = MalariaNetPro().to(DEVICE)\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, scaler):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    loop = tqdm(loader, leave=False)\n",
    "    for images, labels in loop:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE).unsqueeze(1)\n",
    "\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        loop.set_postfix(loss=loss.item(), acc=correct/total)\n",
    "\n",
    "    return running_loss / len(loader), correct / total\n",
    "\n",
    "def validate(loader, model):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE).unsqueeze(1)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return running_loss / len(loader), correct / total\n",
    "\n",
    "\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "# --- PHASE 1  ---\n",
    "print(\"\\n PHASE 1 : WarmUp \")\n",
    "\n",
    "\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "optimizer = optim.AdamW(model.head.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "\n",
    "for epoch in range(3):\n",
    "    train_loss, train_acc = train_one_epoch(train_loader, model, optimizer, scaler)\n",
    "    val_loss, val_acc = validate(val_loader, model)\n",
    "    print(f\"Epoch {epoch+1} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} (Warmup)\")\n",
    "\n",
    "\n",
    "# --- PHASE 2 : FINE-TUNING ---\n",
    "print(\"\\n PHASE 2 : Fine-Tuning \")\n",
    "\n",
    "\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=9)\n",
    "\n",
    "for epoch in range(9):\n",
    "    train_loss, train_acc = train_one_epoch(train_loader, model, optimizer, scaler)\n",
    "    val_loss, val_acc = validate(val_loader, model)\n",
    "    scheduler.step()\n",
    "\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+4} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "\n",
    "    if val_acc > 0.965:\n",
    "        torch.save(model.state_dict(), f'model_best_epoch_{epoch+4}.pth')\n",
    "\n",
    "print(\"\\n Termin\u00e9 ! \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KydngeYwworx"
   },
   "source": [
    "# **4. visualisation des r\u00e9sultats**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1: Courbes Accuracy & Loss"
   ],
   "metadata": {
    "id": "i4Ntn6pExOMc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vb0VPLhbwqLA"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Courbe Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_acc'], label='Train Acc')\n",
    "plt.plot(history['val_acc'], label='Val Acc')\n",
    "plt.title('Pr\u00e9cision du Mod\u00e8le')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Courbe Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.title('Erreur (Loss)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpDKYgTCwwi-"
   },
   "source": [
    "2: Matrice de Confusion & Courbe ROC\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "y_true = []\n",
    "y_probs = []\n",
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(DEVICE)\n",
    "\n",
    "        outputs = model(images)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "\n",
    "        preds = (probs > 0.5).float()\n",
    "\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_probs.extend(probs.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_probs = np.array(y_probs)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# --- MATRICE DE CONFUSION ---\n",
    "plt.subplot(1, 2, 1)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Sain', 'Infect\u00e9'],\n",
    "            yticklabels=['Sain', 'Infect\u00e9'], annot_kws={\"size\": 16})\n",
    "plt.xlabel('Pr\u00e9diction du Mod\u00e8le', fontsize=12)\n",
    "plt.ylabel('R\u00e9alit\u00e9', fontsize=12)\n",
    "plt.title('Matrice de Confusion', fontsize=14)\n",
    "\n",
    "# --- COURBE ROC ---\n",
    "plt.subplot(1, 2, 2)\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Courbe ROC (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux de Faux Positifs (Fausse Alerte)', fontsize=12)\n",
    "plt.ylabel('Taux de Vrais Positifs (D\u00e9tection)', fontsize=12)\n",
    "plt.title('Courbe ROC (Receiver Operating Characteristic)', fontsize=14)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. RAPPORT\n",
    "print(\"\\n\ud83d\udccb Rapport de Classification :\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Sain', 'Infect\u00e9']))"
   ],
   "metadata": {
    "id": "DbSdjxYxwgv1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QF1VgeXQo07V"
   },
   "source": [
    "# **5. Interface Gradio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "veXcsqjpx9YQ"
   },
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_N6D1O4sxU6a"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----BACKEND\n",
    "\n",
    "def predict_malaria_pro(input_image):\n",
    "    if input_image is None:\n",
    "        return None\n",
    "\n",
    "    image = cv2.resize(input_image, (224, 224))\n",
    "\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = (image - mean) / std\n",
    "\n",
    "    image = image.transpose(2, 0, 1)\n",
    "\n",
    "    image_tensor = torch.tensor(image).unsqueeze(0).float().to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        prob_parasitized = torch.sigmoid(output).item()\n",
    "\n",
    "    return {\n",
    "        \"Infect\u00e9 (Malaria) \ud83e\udda0\": prob_parasitized,\n",
    "        \"Sain (Healthy) \ud83e\ude78\": 1 - prob_parasitized\n",
    "    }\n",
    "\n",
    "# ---FRONTEND\n",
    "\n",
    "medical_theme = gr.themes.Soft(\n",
    "    primary_hue=\"cyan\",\n",
    "    secondary_hue=\"slate\",\n",
    ").set(\n",
    "    body_background_fill=\"*secondary_50\",\n",
    "    block_background_fill=\"white\",\n",
    "    button_primary_background_fill=\"*primary_600\",\n",
    "    button_primary_text_color=\"white\",\n",
    ")\n",
    "\n",
    "try:\n",
    "    ex_malade = str(df_parasitized.iloc[10]['path'])\n",
    "    ex_sain = str(df_uninfected.iloc[10]['path'])\n",
    "    example_images = [[ex_malade], [ex_sain]]\n",
    "except:\n",
    "    example_images = None\n",
    "\n",
    "with gr.Blocks(theme=medical_theme, title=\"Malaria AI Diagnostician\") as demo:\n",
    "\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # \ud83d\udd2c AI-Powered Malaria Detector\n",
    "        ### Syst\u00e8me d'aide au diagnostic rapide par Deep Learning.\n",
    "        Chargez une image de frottis sanguin (microscope) pour d\u00e9tecter la pr\u00e9sence du parasite *Plasmodium*.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            image_input = gr.Image(\n",
    "                type=\"numpy\",\n",
    "                label=\"Image Microscope\",\n",
    "                sources=[\"upload\", \"clipboard\"],\n",
    "                height=300\n",
    "            )\n",
    "            analyze_btn = gr.Button(\"Lancer le Diagnostic \u26a1\", variant=\"primary\", size=\"lg\")\n",
    "\n",
    "        with gr.Column(scale=1):\n",
    "            label_output = gr.Label(num_top_classes=2, label=\"R\u00e9sultat de l'IA\")\n",
    "\n",
    "    if example_images:\n",
    "        gr.Markdown(\"### \ud83e\uddea Exemples de test (Cliquez pour charger)\")\n",
    "        gr.Examples(\n",
    "            examples=example_images,\n",
    "            inputs=image_input,\n",
    "            outputs=label_output,\n",
    "            fn=predict_malaria_pro,\n",
    "            run_on_click=True,\n",
    "            label=\"Images de test issues du dataset\"\n",
    "        )\n",
    "\n",
    "    analyze_btn.click(\n",
    "        fn=predict_malaria_pro,\n",
    "        inputs=image_input,\n",
    "        outputs=label_output,\n",
    "        api_name=\"predict\"\n",
    "    )\n",
    "\n",
    "print(\"\ud83d\ude80 Relancement de l'interface corrig\u00e9e...\")\n",
    "demo.launch(share=True, debug=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}